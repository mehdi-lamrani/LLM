{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdi-lamrani/llm/blob/main/PDFSummarizer_langchain_openAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF Summarizer with few lines of code using Gradio, OpenAI and LangChain"
      ],
      "metadata": {
        "id": "yTdPFcqYlvTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install necessary packages"
      ],
      "metadata": {
        "id": "6wL3laYImIY-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Langchain website link](https://docs.langchain.com/docs/)"
      ],
      "metadata": {
        "id": "FeTmdpqYqviZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EkR21whlkn6"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio openai pypdf tiktoken langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "vY7HQRdMpmAO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain import OpenAI, PromptTemplate\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "gMgR1njymD8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15f8430d-9e67-48ba-8123-006671ce2476"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain part\n",
        "#### Function that takes PDF file as input and returns the summary of that PDF\n",
        "- langchain `PyPDFLoader` helps load the PDF\n",
        "- After that we can split the document in smaller chunks\n",
        "- We then use the `load_summarize_chain` to create a summarization chain"
      ],
      "metadata": {
        "id": "bDE4Dm99qdYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_pdf(pdf_file_path):\n",
        "    loader = PyPDFLoader(pdf_file_path)\n",
        "    docs = loader.load_and_split()\n",
        "    chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "    summary = chain.run(docs)\n",
        "    return summary"
      ],
      "metadata": {
        "id": "RZX-spcApXXm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summarize = summarize_pdf(\"/content/A Survey of Large Language Models.pdf\")\n",
        "summarize"
      ],
      "metadata": {
        "id": "4N0oxt_9tGgQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "af6c95e6-cf62-41a0-dd06-8f961f2b9f25"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This article discusses the recent advancements, techniques, and applications of large language models (LLMs) in natural language processing (NLP). It covers topics such as pre-training, adaptation tuning, utilization, and capacity evaluation of LLMs. The article also discusses challenges and techniques for improving LLMs, as well as their potential impact on various fields such as education, law, and finance. It includes a collection of research papers and proceedings on LLMs and highlights their potential for artificial general intelligence. The article also covers methods for evaluating LLMs and their potential applications in different domains and languages.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# just to show you how it works\n",
        "#loader = PyPDFLoader('/content/OA_Paper_2023_04_15.pdf')\n",
        "#doc=loader.load_and_split()\n",
        "#print(len(doc))\n",
        "#doc[0]"
      ],
      "metadata": {
        "id": "MCO5KwFRxd7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a simple gradio UI (if you prefer UI)"
      ],
      "metadata": {
        "id": "PXEcdNg5rKDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input_pdf_path = gr.components.Textbox(label=\"Provide the PDF file path\")\n",
        "output_summary = gr.components.Textbox(label=\"Summary\")\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=summarize_pdf,\n",
        "    inputs=input_pdf_path,\n",
        "    outputs=output_summary,\n",
        "    title=\"PDF Summarizer\",\n",
        "    description=\"Provide PDF file path to get the summary.\",\n",
        ").launch(share=True)"
      ],
      "metadata": {
        "id": "Oth5CY7BrFH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "outputId": "d978a5e8-ee1e-4bdb-90e2-5c3189a518da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://363bc8a78acbdadf68.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://363bc8a78acbdadf68.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "678_yAVTrjg2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}